---
title: "Linear_Model_ClassNote_SK"
author: "Shakiba Kazemian"
date: "2025-04-01"
output:
  html_document: default
  md_document:
    variant: markdown_github
---
## **Class Notes: Introduction to Regression Analysis in R**

### **1. Linear Regression Basics**
- The linear regression model:  
  **y = β₀ + β₁x + ε**, where:
  - **y** = response variable
  - **x** = predictor
  - **β₀** = intercept
  - **β₁** = slope
  - **ε ~ N(0, σ)** = error term (normally distributed)
  
- **Goals**: Estimate slope, intercept, and error (σ).  
- **Objective**: Minimize **SSE (Sum of Squared Errors)**.  
- **P-value**: Measures the probability the result is due to chance.  
  - Null hypothesis: **β₁ = 0** (no slope).
  - Smaller p-values = stronger evidence against the null.

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(lme4)
library(emmeans)
library(multcomp)
library(multcompView)
```

### **2. Regression in R Using `mtcars`**
- Dataset: `mtcars`
- Visualize: Scatterplot with a regression line using `ggplot2`.
```{r}
ggplot(mtcars, aes(x = wt, y = mpg)) +
  geom_smooth(method = lm, se = FALSE, color = "grey") +
  geom_point(aes(color = wt)) +
  xlab("Weight") + 
  ylab("Miles per gallon") +
  scale_colour_gradient(low = "forestgreen", high = "black") +
  theme_classic()
```

- Fit linear model with the function `lm()`:  
```{r}
lm(mpg ~ wt, data = mtcars) # linear relationship between weight (wt) and miles per gallon (mpg)

summary(lm(mpg ~ wt, data = mtcars))
```


### **3. ANOVA and Correlation**

- ANOVA on linear model:
```{r}
anova(lm(mpg ~ wt, data = mtcars)) # Tells us if the effect of wt on mpg is significant
```

- Correlation test:
```{r}
cor.test(mtcars$wt, mtcars$mpg) # Tells us if there is a correlation between wt and mpg
```

### **4. Regression Assumptions**
- Assumptions:
  - y is continuous
  - Error is normal
  - Linear relationship
  - Homoskedasticity (constant σ)
  - Independence
- Violations have minor impacts unless severe.

- Get the residuals from our linear model:
```{r}
model <- lm(mpg~wt, data = mtcars)

ggplot(model, aes(y = .resid, x = .fitted)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

---

## **5. T-tests as Linear Models**
- Use t-tests when x is categorical and y is continuous.
- Example: Fungicide effect on richness.

- Loading richness dataset. 
```{r}
bull.rich <- read.csv("Bull_richness.csv")
```

- Filtering our dataset to include one treatment and growth stage for demonstration of a t-test.
```{r}
library(tidyverse)
bull.rich %>%
  filter(GrowthStage == "V8" & Treatment == "Conv.") %>%
  ggplot(aes(x = Fungicide, y = richness)) + 
  geom_boxplot()
```

- Running the t-test where the null hypothesis is that there is no difference in group means.
```{r}
bull.rich.sub <- bull.rich %>%
  filter(GrowthStage == "V8" & Treatment == "Conv.")

t.test(richness~Fungicide, data = bull.rich.sub)
summary(lm(richness ~ Fungicide, data = bull.rich.sub))
anova(lm(richness ~ Fungicide, data = bull.rich.sub))
```
- T-tests and regression yield the same p-values when assumptions hold.
- The slope β₁ represents the difference between group means.

---

## **6. ANOVA with Multiple Groups**
- Categorical x with more than 2 levels.
- Example: Growth stage effect on richness.

- Filtering our dataset to have only richness in different crop growth stages in the control samples in soybean in conventional management. 
```{r}
bull.rich.sub2 <- bull.rich %>%
  filter(Fungicide == "C" & Treatment == "Conv." & Crop == "Corn")
```

- Visualize the data
```{r}
bull.rich.sub2$GrowthStage <- factor(bull.rich.sub2$GrowthStage, levels = c("V6", "V8", "V15"))

ggplot(bull.rich.sub2, aes(x = GrowthStage, y = richness)) +
  geom_boxplot()
```
- Set up the linear model and run ANOVAs
```{r}
lm.growth <- lm(richness ~ GrowthStage, data = bull.rich.sub2)
summary(lm.growth)
anova(lm.growth)
summary(aov(richness ~ GrowthStage, data = bull.rich.sub2))
```
```
- Model:  
  **y = β₀ + β₁(V8) + β₂(V15) + ε**

### **Post-hoc Tests**
- Use `emmeans` and `multcomp`:
library(emmeans)
library(multcomp)

The lsmeans are the least squared means - they are the means estimated by the linear model. This is in contrast to the arethmatic means which are the means calculated or the average. 
```{r}
lsmeans <- emmeans(lm.growth, ~GrowthStage) # estimate lsmeans of variety within siteXyear
Results_lsmeans <- cld(lsmeans, alpha = 0.05, reversed = TRUE, details = TRUE) # contrast with Tukey ajustment by default. 
Results_lsmeans
```

---

## **7. Interaction Terms**

Lets filter our dataset to include fungicide term. 
```{r}
bull.rich.sub3 <- bull.rich %>%
  filter(Treatment == "Conv." & Crop == "Corn")

bull.rich.sub3$GrowthStage <- factor(bull.rich.sub3$GrowthStage, levels = c("V6", "V8", "V15"))
```

- Check if one variable’s effect depends on another:
```{r}
lm(richness ~ GrowthStage * Fungicide, data = bull.rich.sub3)
```
- Significant interaction implies effect of fungicide varies across stages.
- Visualize with `ggplot2`.

### **Post-hoc on Interaction**
- Split comparison within growth stages:
```{r}
lm.inter <- lm(richness ~ GrowthStage * Fungicide, data = bull.rich.sub3)

lsmeans <- emmeans(lm.inter, ~Fungicide | GrowthStage)
cld(lsmeans, alpha = 0.05)
```

---

## **8. Mixed Effects Models**
- Distinction:
  - **Fixed effects**: affect the mean (e.g., Treatment, Species)
  - **Random effects**: affect variation (e.g., Year, Replicate)

- Use `lme4` package:
```{r}
lme0 <- lm(richness ~ GrowthStage * Fungicide, data = bull.rich.sub3)
lme1 <- lmer(richness ~ GrowthStage*Fungicide + (1|Rep), data = bull.rich.sub3)
```

### **Comparing Models**
- Compare models with and without random effects:
```{r}
anova(lme1, lme0)
```
- Adding random effects can improve model reliability and reduce standard errors.

### **Random vs. Fixed Misclassification**
- You *can* treat a fixed effect as random (e.g., GrowthStage), but you need logical justification.
- Even if it's misclassified, the model will still work, but interpretation differs.

---

## **Summary**
- **Linear models** underpin many statistical tests (t-test, ANOVA, correlation).
- **Visualization** is key before modeling.
- **p-value** interpretation, **model assumptions**, and **model diagnostics** (like residual plots) are essential for proper analysis.
- Mixed models extend linear models to account for variability across random factors.
